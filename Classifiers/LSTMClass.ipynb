{
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Uv68RtGNYdgA",
        "outputId": "fe725a9d-f3c7-4c6b-8d64-f3730280bf46"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow.keras.preprocessing.text import Tokenizer\n",
        "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Embedding, LSTM, Dense, Bidirectional, Dropout, BatchNormalization\n",
        "import json\n",
        "import numpy as np\n",
        "from tensorflow.keras.utils import to_categorical\n",
        "import matplotlib.pyplot as plt"
      ],
      "metadata": {
        "id": "0j58icfGZCy-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "with open(\"path_to_train_articles.json\", \"r\") as f:\n",
        "  train_data = json.load(f)\n",
        "with open(\"path_to_train_articles.json\", \"r\") as f2:\n",
        "  test_data = json.load(f2)"
      ],
      "metadata": {
        "id": "6pwAuW8FWM_c"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Get train and test for 3 class classification"
      ],
      "metadata": {
        "id": "6vSIk2jvzzW_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "X_train = []\n",
        "y_train = []\n",
        "\n",
        "for article in train_data:\n",
        "  X_train.append(article['text'])\n",
        "  y_train.append(article['class_label'])"
      ],
      "metadata": {
        "id": "24MMBTMcUq7L"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X_test = []\n",
        "y_test = []\n",
        "\n",
        "for article in test_data:\n",
        "  X_test.append(article['text'])\n",
        "  y_test.append(article['class_label'])"
      ],
      "metadata": {
        "id": "x20t4Fhh1EpX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Get train and test for binary classification"
      ],
      "metadata": {
        "id": "cJUi6B7Dz8T9"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "X_train = []\n",
        "y_train = []\n",
        "\n",
        "for article in train_data:\n",
        "  X_train.append(article['text'])\n",
        "  y_train.append(article['class_label'] if article['class_label'] == 0 else 1)"
      ],
      "metadata": {
        "id": "TeV4fuCnSYcX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X_test = []\n",
        "y_test = []\n",
        "\n",
        "for article in test_data:\n",
        "  X_test.append(article['text'])\n",
        "  y_test.append(article['class_label'] if article['class_label'] == 0 else 1)"
      ],
      "metadata": {
        "id": "rRrSQWZ_Sxp6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "y_train = to_categorical(y_train, num_classes=3)\n",
        "y_test = to_categorical(y_test, num_classes=3)"
      ],
      "metadata": {
        "id": "EBUFrGtq17Xu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X = X_train + X_test"
      ],
      "metadata": {
        "id": "liXx6eC524cV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 1. Tokenize the text data\n",
        "tokenizer = Tokenizer()\n",
        "tokenizer.fit_on_texts(X)\n",
        "sequences = tokenizer.texts_to_sequences(X_train)"
      ],
      "metadata": {
        "id": "FBjgF5dAZJy4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Automatically determine the vocabulary size\n",
        "vocab_size = len(tokenizer.word_index) + 1"
      ],
      "metadata": {
        "id": "iKGTVmn5ZTjX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#define the max_sequences_lenght:\n",
        "max_sequence_length = max(len(seq) for seq in sequences)"
      ],
      "metadata": {
        "id": "61zm6fmdZWGY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "padded_sequences = pad_sequences(sequences, maxlen=max_sequence_length, padding='post')"
      ],
      "metadata": {
        "id": "KAWXEONpZiDv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = Sequential()\n",
        "model.add(Embedding(input_dim=vocab_size, output_dim=128))\n",
        "model.add(Bidirectional(tf.keras.layers.LSTM(128, return_sequences=True))),\n",
        "model.add(Dropout(0.2))\n",
        "model.add(Bidirectional(tf.keras.layers.LSTM(64))),\n",
        "model.add(Dense(32, activation='relu')),\n",
        "model.add(Dense(3, activation='softmax'))"
      ],
      "metadata": {
        "id": "5b_Bd7nYZlBE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])"
      ],
      "metadata": {
        "id": "9f83MVcEZn4q"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.build()"
      ],
      "metadata": {
        "id": "WeVWJWOXMwUy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "history = model.fit(padded_sequences, y_train, epochs=1, batch_size=600, validation_split=0.1, shuffle=True)"
      ],
      "metadata": {
        "id": "WBZm2CNwaQm6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Plot the loss curves\n",
        "plt.figure(figsize=(10, 6))\n",
        "\n",
        "# Plot training and validation loss\n",
        "plt.plot(history.history['loss'], label='Training Loss')\n",
        "plt.plot(history.history['val_loss'], label='Validation Loss')\n",
        "\n",
        "# Add labels and title\n",
        "plt.xlabel('Epochs')\n",
        "plt.ylabel('Loss')\n",
        "plt.title('Training and Validation Loss')\n",
        "plt.legend()\n",
        "\n",
        "# Show the plot\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "1Ga-QlkEGr9f"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.summary()"
      ],
      "metadata": {
        "id": "I6ujTQ8iaGBR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.utils import plot_model\n",
        "plot_model(model, to_file='/content/modelo.png', show_shapes=True)"
      ],
      "metadata": {
        "id": "eUkNYZfRZyoq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "test_sequences = tokenizer.texts_to_sequences(X_test)\n",
        "max_test_sequence_length = max(len(seq) for seq in test_sequences)\n",
        "padded_test_sequences = pad_sequences(test_sequences, maxlen=max_test_sequence_length, padding='post')"
      ],
      "metadata": {
        "id": "NEinB5K2ctu4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import classification_report\n",
        "import time\n",
        "\n",
        "now = time.time()\n",
        "y_pred = model.predict(padded_test_sequences)\n",
        "print(time.time() - now)\n",
        "y_pred_classes = np.argmax(y_pred, axis=1)\n",
        "y_true_classes = np.argmax(y_test, axis=1)\n",
        "\n",
        "# Generate a classification report\n",
        "report = classification_report(y_true_classes, y_pred_classes)\n",
        "print(report)"
      ],
      "metadata": {
        "id": "2Err58SMN0FB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "\n",
        "# Example n value\n",
        "n = 5  # Number of shortest test strings to select\n",
        "\n",
        "# Get the lengths of each test sequence (before padding)\n",
        "test_sequences_lengths = [len(sequence) for sequence in padded_test_sequences]\n",
        "\n",
        "# Get the indices of the n shortest sequences\n",
        "shortest_indices = np.argsort(test_sequences_lengths)[:-n]\n",
        "\n",
        "# Select the n shortest sequences and their corresponding labels\n",
        "shortest_test_sequences = padded_test_sequences[shortest_indices]\n",
        "shortest_test_labels = np.array(y_test)[shortest_indices]\n",
        "print(X_test[shortest_indices[0]])\n",
        "print(shortest_test_labels)\n",
        "\n",
        "# Evaluate the model on the n shortest test sequences\n",
        "loss, accuracy = model.evaluate(shortest_test_sequences, shortest_test_labels)\n",
        "print(f\"Test accuracy on the {n} shortest sequences: {accuracy}\")"
      ],
      "metadata": {
        "id": "dEyLn-Pn6QBc"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "L4",
      "provenance": [],
      "machine_shape": "hm"
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}